{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy TF agents guide to cartpole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a virtual display for rendering OpenAI gym environments.\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x7F2470F4C9E8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "env = suite_gym.load(env_name)\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedArraySpec(shape=(4,), dtype=dtype('float32'), name='observation', minimum=[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], maximum=[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38])\n",
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n",
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)\n",
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.02717902,  0.02268023,  0.00257027, -0.03471395], dtype=float32),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([-0.02672542,  0.21776523,  0.00187599, -0.32658482], dtype=float32),\n",
      " 'reward': array(1., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# it's output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([1])>, state=(), info=())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "example_environment = tf_py_environment.TFPyEnvironment(suite_gym.load('CartPole-v0'))\n",
    "time_step = example_environment.reset()\n",
    "random_policy.action(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec\n",
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see tutorial 4 or the drivers module.\n",
    "# https://github.com/tensorflow/agents/blob/master/docs/tutorials/4_drivers_tutorial.ipynb \n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to peel one of these off and inspect it.\n",
    "# iter(replay_buffer.as_dataset()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f24484deac8>\n"
     ]
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to see what the dataset iterator is feeding to the agent.\n",
    "# Compare this representation of replay data \n",
    "# to the collection of individual trajectories shown earlier.\n",
    "\n",
    "# iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "step = 200: loss = 60.555328369140625\n",
      "step = 400: loss = 3.238248825073242\n",
      "step = 600: loss = 106.42352294921875\n",
      "step = 800: loss = 76.47171020507812\n",
      "step = 1000: loss = 15.924237251281738\n",
      "step = 1000: Average Return = 200.0\n",
      "step = 1200: loss = 88.29251861572266\n",
      "step = 1400: loss = 526.1328735351562\n",
      "step = 1600: loss = 1685.0777587890625\n",
      "step = 1800: loss = 140.630615234375\n",
      "step = 2000: loss = 2584.775390625\n",
      "step = 2000: Average Return = 200.0\n",
      "step = 2200: loss = 295.13641357421875\n",
      "step = 2400: loss = 11236.8330078125\n",
      "step = 2600: loss = 1974.0684814453125\n",
      "step = 2800: loss = 723.6336669921875\n",
      "step = 3000: loss = 175.63848876953125\n",
      "step = 3000: Average Return = 200.0\n",
      "step = 3200: loss = 10417.8935546875\n",
      "step = 3400: loss = 1074.1591796875\n",
      "step = 3600: loss = 18295.11328125\n",
      "step = 3800: loss = 10617.1708984375\n",
      "step = 4000: loss = 1117.489501953125\n",
      "step = 4000: Average Return = 200.0\n",
      "step = 4200: loss = 458.8933410644531\n",
      "step = 4400: loss = 1159.95849609375\n",
      "step = 4600: loss = 3131.4716796875\n",
      "step = 4800: loss = 8439.5400390625\n",
      "step = 5000: loss = 1220.8912353515625\n",
      "step = 5000: Average Return = 200.0\n",
      "step = 5200: loss = 7031.5302734375\n",
      "step = 5400: loss = 6222.4716796875\n",
      "step = 5600: loss = 5473.4892578125\n",
      "step = 5800: loss = 2858.6884765625\n",
      "step = 6000: loss = 12219.251953125\n",
      "step = 6000: Average Return = 195.0\n",
      "step = 6200: loss = 9517.240234375\n",
      "step = 6400: loss = 9998.0634765625\n",
      "step = 6600: loss = 9590.107421875\n",
      "step = 6800: loss = 34583.328125\n",
      "step = 7000: loss = 22273.234375\n",
      "step = 7000: Average Return = 200.0\n",
      "step = 7200: loss = 188576.09375\n",
      "step = 7400: loss = 5190468.0\n",
      "step = 7600: loss = 98678976.0\n",
      "step = 7800: loss = 37774276.0\n",
      "step = 8000: loss = 17223946.0\n",
      "step = 8000: Average Return = 15.899999618530273\n",
      "step = 8200: loss = 18999338.0\n",
      "step = 8400: loss = 240206512.0\n",
      "step = 8600: loss = 29136468.0\n",
      "step = 8800: loss = 22965424.0\n",
      "step = 9000: loss = 15743240.0\n",
      "step = 9000: Average Return = 113.5\n",
      "step = 9200: loss = 17768400.0\n",
      "step = 9400: loss = 26901468.0\n",
      "step = 9600: loss = 16310612.0\n",
      "step = 9800: loss = 8938611.0\n",
      "step = 10000: loss = 87026656.0\n",
      "step = 10000: Average Return = 200.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.6949995994567875, 250.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
