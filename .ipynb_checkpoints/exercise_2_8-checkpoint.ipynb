{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning: An Introduction\n",
    "\n",
    "### Exercise 2.8\n",
    "\n",
    "k armed bandit problem trying to comapre different methods for tracking nonstationary problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandit\n",
    "def Bandit(arm, B):\n",
    "    B += np.random.normal(0, 0.01, 10)\n",
    "    return B[arm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCB.\n",
    "def UCB(Q, N, t, c):\n",
    "    # Prevent division by zero.\n",
    "    N_temp = np.clip(N, 0.0000001, None)\n",
    "    \n",
    "    A = Q + c*np.sqrt(np.log(t)/N_temp)\n",
    "    return np.argmax(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Bandit.\n",
    "def GradientBandit(Q):\n",
    "    e_Q = np.exp(Q)\n",
    "    P_a = e_Q / np.sum(e_Q)\n",
    "    return np.random.choice(k, p=P_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Epsilon Greedy.\n",
    "def EpsilonGreedy(Q, epsilon):\n",
    "    if np.random.rand(1) > epsilon:\n",
    "        # Exploit\n",
    "        return np.argmax(Q)\n",
    "    else:\n",
    "        # Explore\n",
    "        return np.random.choice(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Greedy with optimistic Q_0 is just EpsilonGreedy with different Initial Q values.\n",
    "def OptimisticInit(Q, Q_0):\n",
    "    Q += Q_0\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\bXXXXX \n",
      "[[ 4.23   4.438  5.174  4.756  5.352]\n",
      " [-2.    -1.     0.     1.     2.   ]]\n",
      "Run time (min) 4.4\n"
     ]
    }
   ],
   "source": [
    "# Setup.\n",
    "start = time.time()\n",
    "#np.random.seed(14)\n",
    "B = np.random.normal(0,1,10)\n",
    "\n",
    "\n",
    "k = 10\n",
    "\n",
    "alpha = 0.1\n",
    "epsilon = 0.0\n",
    "\n",
    "epochs = 20\n",
    "runs = 200000\n",
    "\n",
    "total_rewards = []\n",
    "x_list = []\n",
    "\n",
    "i = 0\n",
    "for x in range(-2, 3):\n",
    "    epoch_rewards = 0\n",
    "    #epsilon = 2**x\n",
    "    #alpha = 2**x\n",
    "    #c = 2**x\n",
    "    Q_0 = 2**x\n",
    "    for e in range(epochs):\n",
    "        run_rewards = 0\n",
    "        Q = np.zeros(k)\n",
    "        N = np.zeros(k, dtype=np.int32)\n",
    "        B = np.random.normal(0,1,10)\n",
    "        Q = OptimisticInit(Q, Q_0)\n",
    "        for t in range(1, runs+1):\n",
    "            a = EpsilonGreedy(Q, epsilon)\n",
    "            #a = GradientBandit(Q)\n",
    "            #a = UCB(Q, N, t, c)\n",
    "            N[a] += 1\n",
    "            r = Bandit(a, B)\n",
    "            Q[a] = Q[a] + alpha* (r - Q[a])\n",
    "            # Only save last 100,000\n",
    "            if t > 100000: run_rewards += r\n",
    "        if e % 2 == 0: print(\"\\b\",int(e/2), sep='',end='')\n",
    "        epoch_rewards += run_rewards/(runs/2)\n",
    "    total_rewards.append(epoch_rewards/(epochs))\n",
    "    x_list.append(x)\n",
    "    print(\"\\bX\", end=' ')\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print(np.array([total_rewards, x_list]))\n",
    "\n",
    "#epsilon_greedy = np.array([total_rewards, x_list])\n",
    "#gradient_bandit = np.array([total_rewards, x_list])\n",
    "#ucb = np.array([total_rewards, x_list])\n",
    "optimistic_initial = np.array([total_rewards, x_list])\n",
    "\n",
    "end = time.time()\n",
    "print(\"Run time (min)\", round((end - start)/60,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7 0.0078125\n",
      "-6 0.015625\n",
      "-5 0.03125\n",
      "-4 0.0625\n",
      "-3 0.125\n",
      "-2 0.25\n",
      "-1 0.5\n",
      "0 1\n",
      "1 2\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "i = -7\n",
    "for x in range(-7, 3):\n",
    "    print(i, 2**x)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate figure 2.6\n",
    "#### Epsilon Greedy\n",
    "[[ 0.694  0.867  0.966  0.979  0.981  0.928]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    " \n",
    "#### Gradient Bandit\n",
    "[[ 0.496  0.57   0.614  0.641  0.652  0.661  0.52 ]\n",
    " [-5.    -4.    -3.    -2.    -1.     0.     1.   ]]\n",
    "\n",
    "#### UCB\n",
    "[[ 1.359  1.359  1.359  1.358  1.312  1.198  0.961]\n",
    " [-4.    -3.    -2.    -1.     0.     1.     2.   ]]\n",
    " \n",
    "#### Optimistic Initialization\n",
    "[[ 0.042  0.042  0.042  0.819  0.819  0.819  0.819  1.11   1.326  1.242]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.    -1.     0.     1.     2.   ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.8\n",
    "#### Epsilon Greedy\n",
    "[[ 6.647  8.365  6.695  5.183  5.488  5.425]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    "\n",
    "[[ 6.315  6.266  5.409  6.223  3.8    4.266]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    " \n",
    "[[ 5.967  5.529  5.256  5.181  5.25   4.734]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    "\n",
    "[[ 5.84   6.548  6.587  5.566  5.491  3.909]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    " \n",
    "Final \n",
    "[[ 5.731  6.572  5.655  6.793  4.782  4.609]\n",
    " [-7.    -6.    -5.    -4.    -3.    -2.   ]]\n",
    "\n",
    " \n",
    "#### Gradient Bandit\n",
    "[[ 5.43   6.521  4.943]\n",
    " [-5.    -4.    -3.   ]]\n",
    " \n",
    " [[ 5.792  5.2    6.176  4.045]\n",
    " [-2.    -1.     0.     1.   ]]\n",
    "\n",
    "\n",
    "#### UCB\n",
    "[[ 4.648  4.627  4.679  5.083  5.131  5.45   5.705]\n",
    " [-4.    -3.    -2.    -1.     0.     1.     2.   ]]\n",
    "\n",
    "#### Optimistic Initialization\n",
    "[[ 4.276  3.625  4.857  4.233  4.46 ]\n",
    " [-2.    -1.     0.     1.     2.   ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
